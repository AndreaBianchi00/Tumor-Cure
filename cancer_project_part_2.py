# -*- coding: utf-8 -*-
"""Cancer Project part_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DVSbNAHrKTJOVr5YH0-pUOoODYyB8ZaO
"""

import pandas as pd

data = pd.read_excel('CancerClean4.xlsx')

data[:] = data[:].replace({'FALSE': 0, 'TRUE': 1})
data[:] = data[:].replace({'Female': 0, 'Male': 1})
data=data.drop(columns=['Gene Panel'])

one_hot_encoded_data = pd.get_dummies(data['Cancer Type'], prefix='CT')
data = data.join(one_hot_encoded_data)
data=data.drop(columns=['Cancer Type'])

one_hot_encoded_data = pd.get_dummies(data['Metastatic Site'], prefix='MS')
data = data.join(one_hot_encoded_data)
data=data.drop(columns=['Metastatic Site'])

one_hot_encoded_data = pd.get_dummies(data['MSI Type'], prefix='MSIT')
data = data.join(one_hot_encoded_data)
data=data.drop(columns=['MSI Type'])

one_hot_encoded_data = pd.get_dummies(data['Organ System'], prefix='OS')
data = data.join(one_hot_encoded_data)
data=data.drop(columns=['Organ System'])

one_hot_encoded_data = pd.get_dummies(data['Primary Tumor Site'], prefix='PTS')
data = data.join(one_hot_encoded_data)
data=data.drop(columns=['Primary Tumor Site'])

one_hot_encoded_data = pd.get_dummies(data['Race Category'], prefix='RC')
data = data.join(one_hot_encoded_data)
data=data.drop(columns=['Race Category'])

one_hot_encoded_data = pd.get_dummies(data['Sample Type'], prefix='ST')
data = data.join(one_hot_encoded_data)
data=data.drop(columns=['Sample Type'])

one_hot_encoded_data = pd.get_dummies(data['Age at First Mets Dx Range'], prefix='AFMDR')
data = data.join(one_hot_encoded_data)
data=data.drop(columns=['Age at First Mets Dx Range'])

one_hot_encoded_data = pd.get_dummies(data['Age at Last Contact Range'], prefix='ALCR')
data = data.join(one_hot_encoded_data)
data=data.drop(columns=['Age at Last Contact Range'])

one_hot_encoded_data = pd.get_dummies(data['Age at Sequencing Range'], prefix='ASR')
data = data.join(one_hot_encoded_data)
data=data.drop(columns=['Age at Sequencing Range'])

one_hot_encoded_data = pd.get_dummies(data['Age at Surgical Procedure Range'], prefix='ASPR')
data = data.join(one_hot_encoded_data)
data=data.drop(columns=['Age at Surgical Procedure Range'])

pd.set_option('display.max_columns', None)

print(data.describe())

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.metrics import Recall
from sklearn.model_selection import train_test_split
from sklearn.utils import class_weight
from sklearn.utils.class_weight import compute_class_weight

X = data.drop(columns=['Distant Mets: Adrenal Gland','Distant Mets: Biliary tract','Distant Mets: Bladder/UT','Distant Mets: Bone','Distant Mets: Bowel','Distant Mets: Breast','Distant Mets: CNS/Brain','Distant Mets: Distant LN','Distant Mets: Female Genital','Distant Mets: Head and Neck','Distant Mets: Intra-Abdominal','Distant Mets: Kidney','Distant Mets: Liver','Distant Mets: Lung','Distant Mets: Male Genital','Distant Mets: Mediastinum','Distant Mets: Ovary','Distant Mets: Pleura','Distant Mets: PNS','Distant Mets: Skin','Distant Mets: Unspecified']).values  # Feature: tutte le colonne tranne 'label'
y = data['Distant Mets: Breast'].values

X = pd.DataFrame(X).fillna(pd.DataFrame(X).mean()).values

# Split del dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Calcolo dei pesi delle classi per gestire il dataset sbilanciato
weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)
class_weights = dict(enumerate(weights))

# Rete neurale
model = Sequential([
    Dense(64, activation='sigmoid', input_shape=(X_train.shape[1],)),
    Dropout(0.5),
    Dense(32, activation='sigmoid'),
    Dropout(0.5),
    Dense(16, activation='sigmoid'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

# Compilazione del modello
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[Recall()])

# Addestramento del modello
model.fit(X_train, y_train, epochs=30, batch_size=64, class_weight=class_weights, validation_split=0.2)

# Valutazione del modello
loss, recall = model.evaluate(X_test, y_test)
print(f'Test loss: {loss}, Test recall: {recall}')

from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Effettua le predizioni sul set di test
y_pred_prob = model.predict(X_test)
y_pred = [1 if prob > 0.5 else 0 for prob in y_pred_prob]

# Calcola la matrice di confusione
conf_matrix = confusion_matrix(y_test, y_pred)

# Visualizza la matrice di confusione
fig, ax = plt.subplots(figsize=(5, 5))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', square=True,
            xticklabels=['Non Cancro', 'Cancro'], yticklabels=['Non Cancro', 'Cancro'])
plt.ylabel('Etichetta reale')
plt.xlabel('Etichetta predetta')
plt.title('Matrice di Confusione')
plt.show()

column_names = data.columns
column_names=column_names.drop(['Distant Mets: Adrenal Gland','Distant Mets: Biliary tract','Distant Mets: Bladder/UT','Distant Mets: Bone','Distant Mets: Bowel','Distant Mets: Breast','Distant Mets: CNS/Brain','Distant Mets: Distant LN','Distant Mets: Female Genital','Distant Mets: Head and Neck','Distant Mets: Intra-Abdominal','Distant Mets: Kidney','Distant Mets: Liver','Distant Mets: Lung','Distant Mets: Male Genital','Distant Mets: Mediastinum','Distant Mets: Ovary','Distant Mets: Pleura','Distant Mets: PNS','Distant Mets: Skin','Distant Mets: Unspecified'])

print("Nomi delle colonne nel dataset:", column_names)

column_names_array = column_names.to_numpy()
patient_array=np.zeros(170)

for i in range (170):
    patient_array[i]=input(column_names_array[i])

patient_array=patient_array.reshape(1,170)
y_pred_patient = model.predict(patient_array)
print('the probability that this patient has a metastasis in the breast is: ', y_pred_patient)

import numpy as np

import pandas as pd

import tensorflow as tf

from tensorflow.keras.models import Sequential

from tensorflow.keras.layers import Dense, Dropout

from tensorflow.keras.metrics import Recall

from tensorflow.keras.metrics import Precision

from sklearn.model_selection import train_test_split

from sklearn.utils.class_weight import compute_class_weight

# Assumiamo che `data` sia giÃ  stato definito

# X e y sono definiti come nel tuo esempio

X = pd.DataFrame(X).fillna(pd.DataFrame(X).mean()).values

# Primo split: separa il set di test dal resto

X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Secondo split: divide il rimanente dataset in set di training e validation

X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2 del dataset originale

# Calcolo dei pesi delle classi per gestire il dataset sbilanciato

weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)

class_weights = dict(enumerate(weights))

# Definizione della rete neurale

model = Sequential([

    Dense(512, activation='sigmoid', input_shape=(X_train.shape[1],)),

    Dropout(0.5),

    Dense(128, activation='sigmoid'),

    Dropout(0.5),

    Dense(64, activation='sigmoid'),

    Dropout(0.5),

    Dense(1, activation='sigmoid')

])

# Compilazione del modello

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[Precision()])

# Addestramento del modello con il set di validation

model.fit(X_train, y_train, epochs=120, batch_size=32, class_weight=class_weights, validation_data=(X_val, y_val))

# Valutazione del modello sul set di test

loss, precision = model.evaluate(X_test, y_test)

print(f'Test loss: {loss}, Test precision: {precision}')

# Effettua le predizioni sul set di test
y_pred_prob = model.predict(X_test)
y_pred = [1 if prob > 0.5 else 0 for prob in y_pred_prob]

# Calcola la matrice di confusione
conf_matrix = confusion_matrix(y_test, y_pred)

# Visualizza la matrice di confusione
fig, ax = plt.subplots(figsize=(5, 5))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', square=True,
            xticklabels=['Non Cancro', 'Cancro'], yticklabels=['Non Cancro', 'Cancro'])
plt.ylabel('Etichetta reale')
plt.xlabel('Etichetta predetta')
plt.title('Matrice di Confusione')
plt.show()

from sklearn.metrics import recall_score, accuracy_score, precision_score

# Calcolo di Recall, Accuracy e Precision
recall = recall_score(y_test, y_pred, average='binary')
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='binary')

print(f"Recall: {recall}")
print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")

parameters = {
    'n_neurons': [125, 250, 900, 125, 250, 900, 125, 250, 900 ],
    'n_layers': [6, 6, 6, 5, 5, 5, 4, 4, 4],
    'recall': [0.88235, 0.86275, 0.86275, 0.92157, 0.86275, 0.90196, 0.90196, 0.90196, 0.82353],
    'accuracy': [0.85512, 0.81551, 0.87892, 0.63000, 0.88713, 0.77714, 0.79787, 0.77529, 0.92243],
    'precision': [0.06040, 0.04701, 0.07018, 0.02546, 0.07496, 0.04082, 0.04483, 0.04049, 0.10219]
}
results_df = pd.DataFrame(parameters)

for metric in ['recall', 'accuracy', 'precision']:
    # Pivot il DataFrame per prepararlo per la heatmap
    pivot_df = results_df.pivot("n_neurons", "n_layers", metric)
    # Crea e mostra la heatmap
    plt.figure(figsize=(6, 4))
    sns.heatmap(pivot_df, annot=True, cmap="Reds", fmt=".2f")
    plt.title(f"Heatmap of {metric.capitalize()}")
    plt.ylabel("number of neurons")
    plt.xlabel("number of layers")
    plt.show()

data2=data.loc[data['Sex'] == 1]
pd.set_option('display.max_columns', None)

X = data2.drop(columns=['Distant Mets: Adrenal Gland','Distant Mets: Biliary tract','Distant Mets: Bladder/UT','Distant Mets: Bone','Distant Mets: Bowel','Distant Mets: Breast','Distant Mets: CNS/Brain','Distant Mets: Distant LN','Distant Mets: Female Genital','Distant Mets: Head and Neck','Distant Mets: Intra-Abdominal','Distant Mets: Kidney','Distant Mets: Liver','Distant Mets: Lung','Distant Mets: Male Genital','Distant Mets: Mediastinum','Distant Mets: Ovary','Distant Mets: Pleura','Distant Mets: PNS','Distant Mets: Skin','Distant Mets: Unspecified']).values  # Feature: tutte le colonne tranne 'label'
y = data2['Distant Mets: Breast'].values

X = pd.DataFrame(X).fillna(pd.DataFrame(X).mean()).values

X = pd.DataFrame(X).fillna(pd.DataFrame(X).mean()).values

# Primo split: separa il set di test dal resto

X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Secondo split: divide il rimanente dataset in set di training e validation

X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2 del dataset originale

# Calcolo dei pesi delle classi per gestire il dataset sbilanciato

weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)

class_weights = dict(enumerate(weights))

# Definizione della rete neurale

model = Sequential([

    Dense(256, activation='sigmoid', input_shape=(X_train.shape[1],)),

    Dropout(0.5),

    Dense(128, activation='sigmoid'),

    Dropout(0.5),

    Dense(64, activation='sigmoid'),

    Dropout(0.5),

    Dense(1, activation='sigmoid')

])

# Compilazione del modello

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[Recall()])

# Addestramento del modello con il set di validation

model.fit(X_train, y_train, epochs=100, batch_size=32, class_weight=class_weights, validation_data=(X_val, y_val))

# Valutazione del modello sul set di test

loss, recall = model.evaluate(X_test, y_test)

print(f'Test loss: {loss}, Test recall: {recall}')

# Effettua le predizioni sul set di test
y_pred_prob = model.predict(X_test)
y_pred = [1 if prob > 0.5 else 0 for prob in y_pred_prob]

# Calcola la matrice di confusione
conf_matrix = confusion_matrix(y_test, y_pred)

# Visualizza la matrice di confusione
fig, ax = plt.subplots(figsize=(5, 5))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', square=True,
            xticklabels=['Non Cancro', 'Cancro'], yticklabels=['Non Cancro', 'Cancro'])
plt.ylabel('Etichetta reale')
plt.xlabel('Etichetta predetta')
plt.title('Matrice di Confusione')
plt.show()

from sklearn.metrics import recall_score, accuracy_score, precision_score

# Calcolo di Recall, Accuracy e Precision
recall = recall_score(y_test, y_pred, average='binary')
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='binary')

print(f"Recall: {recall}")
print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from math import pi

# Dati di esempio
data2 = {
    'Group': ['Female', 'Male', 'White', 'Black', 'Old', 'Young'],
    'Accuratezza': [0.821, 0.759, 0.81,0.855,0.79,0.757],
    'Recall': [0.75, 0.429, 0.83, 0.77,0.8,0.857],
}

data2 = {
    'Group': ['Accuracy', 'Recall'],
    'Female': [0.821, 0.75],
    'Male': [0.759, 0.429],
    'White': [0.81, 0.83],
    'Black': [0.855, 0.77],
    'Old': [0.79, 0.8],
    'Young': [0.757, 0.857],
}
data2 = pd.DataFrame(data2)

# Numero di variabili
categories = list(data2)[1:]
N = len(categories)

# Angoli per ogni asse
angles = [n / float(N) * 2 * pi for n in range(N)]
angles += angles[:1]

# Inizializzazione del grafico radar
ax = plt.subplot(111, polar=True)

# Primo asse in alto
ax.set_theta_offset(pi / 2)
ax.set_theta_direction(-1)

# Disegna un asse per ogni attributo e aggiungi le etichette
plt.xticks(angles[:-1], categories)

# Disegna gli yticks
ax.set_rlabel_position(0)
plt.yticks([0.25,0.5,0.75], ["0.25","0.5","0.75"], color="grey", size=7)
plt.ylim(0,1)

# Aggiungi i dati per il Gruppo A
values = data2.loc[0].drop('Group').values.flatten().tolist()
values += values[:1]
ax.plot(angles, values, linewidth=1, linestyle='solid', label='Accuracy')
ax.fill(angles, values, 'b', alpha=0.1)


# Aggiungi la legenda
plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))

plt.show()