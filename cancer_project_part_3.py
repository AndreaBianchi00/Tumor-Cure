# -*- coding: utf-8 -*-
"""Cancer Project part_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11ZlDJat2sgVsRGOEqlWxIKc-FkRtAEyn
"""

import pandas as pd
from google.colab import files
uploaded = files.upload()

data = pd.read_excel('CancerClean4.xlsx')

import pandas as pd

data = pd.read_excel('CancerClean4.xlsx')

data[:] = data[:].replace({'FALSE': 0, 'TRUE': 1})
data[:] = data[:].replace({'Female': 0, 'Male': 1})
data=data.drop(columns=['Gene Panel'])

one_hot_encoded_data = pd.get_dummies(data['Cancer Type'], prefix='CT')
data = data.join(one_hot_encoded_data)
data=data.drop(columns=['Cancer Type'])

one_hot_encoded_data = pd.get_dummies(data['Metastatic Site'], prefix='MS')
data = data.join(one_hot_encoded_data)
data=data.drop(columns=['Metastatic Site'])

one_hot_encoded_data = pd.get_dummies(data['MSI Type'], prefix='MSIT')
data = data.join(one_hot_encoded_data)
data=data.drop(columns=['MSI Type'])

one_hot_encoded_data = pd.get_dummies(data['Organ System'], prefix='OS')
data = data.join(one_hot_encoded_data)
data=data.drop(columns=['Organ System'])

one_hot_encoded_data = pd.get_dummies(data['Primary Tumor Site'], prefix='PTS')
data = data.join(one_hot_encoded_data)
data=data.drop(columns=['Primary Tumor Site'])

one_hot_encoded_data = pd.get_dummies(data['Sample Type'], prefix='ST')
data = data.join(one_hot_encoded_data)
data=data.drop(columns=['Sample Type'])

one_hot_encoded_data = pd.get_dummies(data['Age at First Mets Dx Range'], prefix='AFMDR')
data = data.join(one_hot_encoded_data)
data=data.drop(columns=['Age at First Mets Dx Range'])

one_hot_encoded_data = pd.get_dummies(data['Age at Sequencing Range'], prefix='ASR')
data = data.join(one_hot_encoded_data)
data=data.drop(columns=['Age at Sequencing Range'])

one_hot_encoded_data = pd.get_dummies(data['Age at Surgical Procedure Range'], prefix='ASPR')
data = data.join(one_hot_encoded_data)
data=data.drop(columns=['Age at Surgical Procedure Range'])

one_hot_encoded_data = pd.get_dummies(data['Age at Last Contact Range'], prefix='ALCR')
data = data.join(one_hot_encoded_data)
data=data.drop(columns=['Age at Last Contact Range'])

one_hot_encoded_data = pd.get_dummies(data['Race Category'], prefix='RC')
data = data.join(one_hot_encoded_data)
data=data.drop(columns=['Race Category'])

pd.set_option('display.max_columns', None)

print(data.describe())

data[:] = data[:].replace({'White': 0})

data[:] = data[:].replace({'Asian-far east/indian subcont': 0 })
data[:] = data[:].replace({'Black or african american': 1})
data[:] = data[:].replace({'Native american-am ind/alaska': 1})
data[:] = data[:].replace({'Native hawaiian or pacific isl': 1})
data[:] = data[:].replace({'Unknown': 1})
data[:] = data[:].replace({'Pt refused to answer': 1})
data[:] = data[:].replace({'No value entered': 1})
data[:] = data[:].replace({'Other': 1})
data.describe()

data[:] = data[:].replace({'15.0-19.9': 0})

data[:] = data[:].replace({'40.0-44.9': 0})
data[:] = data[:].replace({'45.0-49.9': 0})
data[:] = data[:].replace({'60.0-64.9': 0})
data[:] = data[:].replace({'75.0-79.9': 1})
data[:] = data[:].replace({'70.0-74.9': 1})
data[:] = data[:].replace({'65.0-69.9': 0})
data[:] = data[:].replace({'50.0-54.9': 0})
data[:] = data[:].replace({'55.0-59.9': 0})
data[:] = data[:].replace({'80.0-84.9': 1})
data[:] = data[:].replace({'25.0-29.9': 0})
data[:] = data[:].replace({'35.0-39.9': 0})
data[:] = data[:].replace({'30.0-34.9': 0})
data[:] = data[:].replace({'85.0-89.9': 1})
data[:] = data[:].replace({'20.0-24.9': 0})
data[:] = data[:].replace({'90.0-94.9': 1})
data[:] = data[:].replace({'15.0-19.9': 0})

data = data.drop(data[data['Age at Last Contact Range'] == 'No'].index)

data.describe()

data = data[data['Race Category'] == 0]

data = data[data['Sex'] == 0]

data = data[data['Age at Last Contact Range'] == 0]

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.metrics import Recall
from sklearn.model_selection import train_test_split
from sklearn.utils import class_weight
from sklearn.utils.class_weight import compute_class_weight


X = data.drop(columns=['Distant Mets: Adrenal Gland','Distant Mets: Biliary tract','Distant Mets: Bladder/UT','Distant Mets: Bone','Distant Mets: Bowel','Distant Mets: Breast','Distant Mets: CNS/Brain','Distant Mets: Distant LN','Distant Mets: Female Genital','Distant Mets: Head and Neck','Distant Mets: Intra-Abdominal','Distant Mets: Kidney','Distant Mets: Liver','Distant Mets: Lung','Distant Mets: Male Genital','Distant Mets: Mediastinum','Distant Mets: Ovary','Distant Mets: Pleura','Distant Mets: PNS','Distant Mets: Skin','Distant Mets: Unspecified']).values  # Feature: tutte le colonne tranne 'label'
y = data['Distant Mets: Breast'].values

X = pd.DataFrame(X).fillna(pd.DataFrame(X).mean()).values

# Split del dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Calcolo dei pesi delle classi per gestire il dataset sbilanciato
weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)
class_weights = dict(enumerate(weights))

# Rete neurale
model = Sequential([
    Dense(512, activation='sigmoid', input_shape=(X_train.shape[1],)),
    Dropout(0.5),
    Dense(256, activation='sigmoid'),
    Dropout(0.5),
    Dense(64, activation='sigmoid'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

# Compilazione del modello
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[Recall()])

# Addestramento del modello
model.fit(X_train, y_train, epochs=120, batch_size=64, class_weight=class_weights, validation_split=0.2)

# Valutazione del modello
loss, recall = model.evaluate(X_test, y_test)
print(f'Test loss: {loss}, Test recall: {recall}')

from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Effettua le predizioni sul set di test
y_pred_prob = model.predict(X_test)
y_pred = [1 if prob > 0.5 else 0 for prob in y_pred_prob]

# Calcola la matrice di confusione
conf_matrix = confusion_matrix(y_test, y_pred)

# Visualizza la matrice di confusione
fig, ax = plt.subplots(figsize=(5, 5))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', square=True,
            xticklabels=['Non Cancro', 'Cancro'], yticklabels=['Non Cancro', 'Cancro'])
plt.ylabel('Etichetta reale')
plt.xlabel('Etichetta predetta')
plt.title('Matrice di Confusione')
plt.show()

import numpy as np

import pandas as pd

import tensorflow as tf

from tensorflow.keras.models import Sequential

from tensorflow.keras.layers import Dense, Dropout

from tensorflow.keras.metrics import Recall

from sklearn.model_selection import train_test_split

from sklearn.utils.class_weight import compute_class_weight

# Assumiamo che `data` sia già stato definito

# X e y sono definiti come nel tuo esempio

X = pd.DataFrame(X).fillna(pd.DataFrame(X).mean()).values

# Primo split: separa il set di test dal resto

X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Secondo split: divide il rimanente dataset in set di training e validation

X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2 del dataset originale

# Calcolo dei pesi delle classi per gestire il dataset sbilanciato

weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)

class_weights = dict(enumerate(weights))

# Definizione della rete neurale

model = Sequential([

    Dense(128, activation='sigmoid', input_shape=(X_train.shape[1],)),

    Dropout(0.35),

    Dense(64, activation='sigmoid'),

    Dropout(0.35),

    Dense(32, activation='sigmoid'),

    Dropout(0.35),

    Dense(1, activation='sigmoid')

])

# Compilazione del modello

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[Recall()])

# Addestramento del modello con il set di validation

model.fit(X_train, y_train, epochs=100, batch_size=64, class_weight=class_weights, validation_data=(X_val, y_val))

# Valutazione del modello sul set di test

loss, recall = model.evaluate(X_test, y_test)

print(f'Test loss: {loss}, Test recall: {recall}')

# Effettua le predizioni sul set di test
y_pred_prob = model.predict(X_test)
y_pred = [1 if prob > 0.5 else 0 for prob in y_pred_prob]

# Calcola la matrice di confusione
conf_matrix = confusion_matrix(y_test, y_pred)

# Visualizza la matrice di confusione
fig, ax = plt.subplots(figsize=(5, 5))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', square=True,
            xticklabels=['Non Cancro', 'Cancro'], yticklabels=['Non Cancro', 'Cancro'])
plt.ylabel('Etichetta reale')
plt.xlabel('Etichetta predetta')
plt.title('Matrice di Confusione')
plt.show()

from sklearn.metrics import recall_score, accuracy_score, precision_score

# Calcolo di Recall, Accuracy e Precision
recall = recall_score(y_test, y_pred, average='binary')
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='binary')

print(f"Recall: {recall}")
print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")

fairnessMR = abs(accuracy_male_white - accuracy_male_black)
print(f"Differenza assoluta nell'accuratezza (Male Fairness): {fairnessMR}")

fairnessFR = abs(accuracy_female_white - accuracy_female_black)
print(f"Differenza assoluta nell'accuratezza (Female Fairness): {fairnessFR}")

fairnessWG = abs(accuracy_female_white - accuracy_male_white)
print(f"Differenza assoluta nell'accuratezza (White Fairness): {fairnessWG}")

fairnessBG = abs(accuracy_female_black - accuracy_male_black)
print(f"Differenza assoluta nell'accuratezza (Black Fairness): {fairnessBG}")

fairnessGI1 = abs(accuracy_female_black - accuracy_male_white)
print(f"Differenza assoluta nell'accuratezza (GI1 Fairness): {fairnessGI1}")

fairnessGI2 = abs(accuracy_male_black - accuracy_female_white)
print(f"Differenza assoluta nell'accuratezza (GI2 Fairness): {fairnessGI2}")

import numpy as np

valori = [fairnessBG , fairnessWG, fairnessFR, fairnessMR,fairnessGI1, fairnessGI2]

# Calcolo della media utilizzando numpy
media = np.mean(valori)

print("La media dei valori è:", media)

accuracy_old=0.7984986171473726
accuracy_young=0.7572440437862202
age_fairness = abs(accuracy_old - accuracy_young)
print(f"Differenza assoluta nell'accuratezza (Age Fairness): {age_fairness}")

recall_old=0.8
recall_young= 0.857142857142857
age_fairness = abs(recall_old - recall_young)
print(f"Differenza assoluta nella recall (Age Fairness): {age_fairness}")

accuracy_male=0.7587260034904014
accuracy_female=0.8209996125532739
gender_fairness = abs(accuracy_male - accuracy_female)
print(f"Differenza assoluta nell'accuratezza (Gender Fairness): {gender_fairness}")

recall_male=0.42857142855
recall_female= 0.75
gender_fairness = abs(recall_male - recall_female)
print(f"Differenza assoluta nella recall (Gender Fairness): {gender_fairness}")

accuracy_white=0.8047024952015355
accuracy_black=0.8553191489361702
race_fairness = abs(accuracy_white - accuracy_black)
print(f"Differenza assoluta nell'accuratezza (Rcae Fairness): {race_fairness}")

recall_white=0.8292682926829268
recall_black= 0.7692307692307693
race_fairness = abs(recall_white - recall_black)
print(f"Differenza assoluta nella recall (Race Fairness): {race_fairness}")